{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "885544ef-cfc0-4763-b571-1f825ff20839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "--- Teacher Training ---\n",
      "Teacher | Step 500/15000 | Train Acc: 0.9453 | Test Acc: 0.9546\n",
      "Teacher | Step 1000/15000 | Train Acc: 0.9297 | Test Acc: 0.9702\n",
      "Teacher | Step 1500/15000 | Train Acc: 0.9219 | Test Acc: 0.9783\n",
      "Teacher | Step 2000/15000 | Train Acc: 0.9297 | Test Acc: 0.9824\n",
      "Teacher | Step 2500/15000 | Train Acc: 0.9453 | Test Acc: 0.9838\n",
      "Teacher | Step 3000/15000 | Train Acc: 0.9922 | Test Acc: 0.9849\n",
      "Teacher | Step 3500/15000 | Train Acc: 0.9766 | Test Acc: 0.9874\n",
      "Teacher | Step 4000/15000 | Train Acc: 0.9844 | Test Acc: 0.9887\n",
      "Teacher | Step 4500/15000 | Train Acc: 0.9688 | Test Acc: 0.9890\n",
      "Teacher | Step 5000/15000 | Train Acc: 0.9688 | Test Acc: 0.9901\n",
      "Teacher | Step 5500/15000 | Train Acc: 0.9844 | Test Acc: 0.9913\n",
      "Teacher | Step 6000/15000 | Train Acc: 1.0000 | Test Acc: 0.9906\n",
      "Teacher | Step 6500/15000 | Train Acc: 0.9844 | Test Acc: 0.9913\n",
      "Teacher | Step 7000/15000 | Train Acc: 0.9766 | Test Acc: 0.9919\n",
      "Teacher | Step 7500/15000 | Train Acc: 0.9922 | Test Acc: 0.9920\n",
      "Teacher | Step 8000/15000 | Train Acc: 0.9922 | Test Acc: 0.9923\n",
      "Teacher | Step 8500/15000 | Train Acc: 0.9844 | Test Acc: 0.9921\n",
      "Teacher | Step 9000/15000 | Train Acc: 0.9922 | Test Acc: 0.9926\n",
      "Teacher | Step 9500/15000 | Train Acc: 0.9844 | Test Acc: 0.9920\n",
      "Teacher | Step 10000/15000 | Train Acc: 0.9766 | Test Acc: 0.9930\n",
      "Teacher | Step 10500/15000 | Train Acc: 0.9844 | Test Acc: 0.9933\n",
      "Teacher | Step 11000/15000 | Train Acc: 0.9766 | Test Acc: 0.9933\n",
      "Teacher | Step 11500/15000 | Train Acc: 1.0000 | Test Acc: 0.9936\n",
      "Teacher | Step 12000/15000 | Train Acc: 0.9922 | Test Acc: 0.9938\n",
      "Teacher | Step 12500/15000 | Train Acc: 1.0000 | Test Acc: 0.9935\n",
      "Teacher | Step 13000/15000 | Train Acc: 1.0000 | Test Acc: 0.9939\n",
      "Teacher | Step 13500/15000 | Train Acc: 0.9844 | Test Acc: 0.9943\n",
      "Teacher | Step 14000/15000 | Train Acc: 1.0000 | Test Acc: 0.9943\n",
      "Teacher | Step 14500/15000 | Train Acc: 0.9844 | Test Acc: 0.9939\n",
      "Teacher | Step 15000/15000 | Train Acc: 0.9766 | Test Acc: 0.9942\n",
      "--- Teacher Training Finished ---\n",
      "Teacher model saved to ./models/teacher1.ckpt\n",
      "Accuracy graph for Teacher Model saved as teacher_model_accuracy_history.png\n",
      "\n",
      "--- Baseline Student Training ---\n",
      "Baseline Student | Step 500/15000 | Train Acc: 0.7900 | Test Acc: 0.8004\n",
      "Baseline Student | Step 1000/15000 | Train Acc: 0.8700 | Test Acc: 0.8947\n",
      "Baseline Student | Step 1500/15000 | Train Acc: 0.9000 | Test Acc: 0.8953\n",
      "Baseline Student | Step 2000/15000 | Train Acc: 0.9100 | Test Acc: 0.9045\n",
      "Baseline Student | Step 2500/15000 | Train Acc: 0.8800 | Test Acc: 0.9088\n",
      "Baseline Student | Step 3000/15000 | Train Acc: 0.8800 | Test Acc: 0.9152\n",
      "Baseline Student | Step 3500/15000 | Train Acc: 0.9500 | Test Acc: 0.9142\n",
      "Baseline Student | Step 4000/15000 | Train Acc: 0.9200 | Test Acc: 0.9156\n",
      "Baseline Student | Step 4500/15000 | Train Acc: 0.9500 | Test Acc: 0.9196\n",
      "Baseline Student | Step 5000/15000 | Train Acc: 0.9400 | Test Acc: 0.9198\n",
      "Baseline Student | Step 5500/15000 | Train Acc: 0.9200 | Test Acc: 0.9206\n",
      "Baseline Student | Step 6000/15000 | Train Acc: 0.9000 | Test Acc: 0.9200\n",
      "Baseline Student | Step 6500/15000 | Train Acc: 0.9400 | Test Acc: 0.9230\n",
      "Baseline Student | Step 7000/15000 | Train Acc: 0.9100 | Test Acc: 0.9236\n",
      "Baseline Student | Step 7500/15000 | Train Acc: 0.9000 | Test Acc: 0.9219\n",
      "Baseline Student | Step 8000/15000 | Train Acc: 0.9300 | Test Acc: 0.9243\n",
      "Baseline Student | Step 8500/15000 | Train Acc: 0.9600 | Test Acc: 0.9238\n",
      "Baseline Student | Step 9000/15000 | Train Acc: 0.9300 | Test Acc: 0.9243\n",
      "Baseline Student | Step 9500/15000 | Train Acc: 0.9400 | Test Acc: 0.9242\n",
      "Baseline Student | Step 10000/15000 | Train Acc: 0.9100 | Test Acc: 0.9290\n",
      "Baseline Student | Step 10500/15000 | Train Acc: 0.9300 | Test Acc: 0.9285\n",
      "Baseline Student | Step 11000/15000 | Train Acc: 0.9600 | Test Acc: 0.9299\n",
      "Baseline Student | Step 11500/15000 | Train Acc: 0.9700 | Test Acc: 0.9302\n",
      "Baseline Student | Step 12000/15000 | Train Acc: 0.9100 | Test Acc: 0.9325\n",
      "Baseline Student | Step 12500/15000 | Train Acc: 0.9100 | Test Acc: 0.9336\n",
      "Baseline Student | Step 13000/15000 | Train Acc: 0.9500 | Test Acc: 0.9351\n",
      "Baseline Student | Step 13500/15000 | Train Acc: 0.9200 | Test Acc: 0.9360\n",
      "Baseline Student | Step 14000/15000 | Train Acc: 0.9600 | Test Acc: 0.9379\n",
      "Baseline Student | Step 14500/15000 | Train Acc: 0.9400 | Test Acc: 0.9365\n",
      "Baseline Student | Step 15000/15000 | Train Acc: 0.9300 | Test Acc: 0.9400\n",
      "--- Baseline Student Training Finished ---\n",
      "\n",
      "--- Distilled Student: alpha=0.08, temp=7 ---\n",
      "Teacher model loaded.\n",
      "Distilled Student | Step 500/15000 | Train Acc: 0.8600 | Test Acc: 0.8925\n",
      "Distilled Student | Step 1000/15000 | Train Acc: 0.8900 | Test Acc: 0.9182\n",
      "Distilled Student | Step 1500/15000 | Train Acc: 0.9000 | Test Acc: 0.9334\n",
      "Distilled Student | Step 2000/15000 | Train Acc: 0.9600 | Test Acc: 0.9427\n",
      "Distilled Student | Step 2500/15000 | Train Acc: 0.9600 | Test Acc: 0.9509\n",
      "Distilled Student | Step 3000/15000 | Train Acc: 0.9300 | Test Acc: 0.9544\n",
      "Distilled Student | Step 3500/15000 | Train Acc: 0.9700 | Test Acc: 0.9610\n",
      "Distilled Student | Step 4000/15000 | Train Acc: 1.0000 | Test Acc: 0.9636\n",
      "Distilled Student | Step 4500/15000 | Train Acc: 0.9500 | Test Acc: 0.9667\n",
      "Distilled Student | Step 5000/15000 | Train Acc: 0.9700 | Test Acc: 0.9694\n",
      "Distilled Student | Step 5500/15000 | Train Acc: 0.9500 | Test Acc: 0.9717\n",
      "Distilled Student | Step 6000/15000 | Train Acc: 0.9700 | Test Acc: 0.9723\n",
      "Distilled Student | Step 6500/15000 | Train Acc: 0.9600 | Test Acc: 0.9741\n",
      "Distilled Student | Step 7000/15000 | Train Acc: 0.9800 | Test Acc: 0.9759\n",
      "Distilled Student | Step 7500/15000 | Train Acc: 0.9700 | Test Acc: 0.9761\n",
      "Distilled Student | Step 8000/15000 | Train Acc: 0.9900 | Test Acc: 0.9768\n",
      "Distilled Student | Step 8500/15000 | Train Acc: 0.9600 | Test Acc: 0.9785\n",
      "Distilled Student | Step 9000/15000 | Train Acc: 0.9500 | Test Acc: 0.9789\n",
      "Distilled Student | Step 9500/15000 | Train Acc: 0.9700 | Test Acc: 0.9788\n",
      "Distilled Student | Step 10000/15000 | Train Acc: 0.9700 | Test Acc: 0.9789\n",
      "Distilled Student | Step 10500/15000 | Train Acc: 0.9800 | Test Acc: 0.9806\n",
      "Distilled Student | Step 11000/15000 | Train Acc: 0.9800 | Test Acc: 0.9811\n",
      "Distilled Student | Step 11500/15000 | Train Acc: 0.9800 | Test Acc: 0.9801\n",
      "Distilled Student | Step 12000/15000 | Train Acc: 0.9700 | Test Acc: 0.9807\n",
      "Distilled Student | Step 12500/15000 | Train Acc: 0.9800 | Test Acc: 0.9816\n",
      "Distilled Student | Step 13000/15000 | Train Acc: 0.9800 | Test Acc: 0.9818\n",
      "Distilled Student | Step 13500/15000 | Train Acc: 1.0000 | Test Acc: 0.9817\n",
      "Distilled Student | Step 14000/15000 | Train Acc: 0.9900 | Test Acc: 0.9821\n",
      "Distilled Student | Step 14500/15000 | Train Acc: 0.9800 | Test Acc: 0.9822\n",
      "Distilled Student | Step 15000/15000 | Train Acc: 0.9800 | Test Acc: 0.9822\n",
      "Distilled student model saved to ./models/student_a0.08_t7.ckpt\n",
      "\n",
      "--- Distilled Student: alpha=0.5, temp=1 ---\n",
      "Teacher model loaded.\n",
      "Distilled Student | Step 500/15000 | Train Acc: 0.8700 | Test Acc: 0.8711\n",
      "Distilled Student | Step 1000/15000 | Train Acc: 0.8600 | Test Acc: 0.8863\n",
      "Distilled Student | Step 1500/15000 | Train Acc: 0.8400 | Test Acc: 0.9039\n",
      "Distilled Student | Step 2000/15000 | Train Acc: 0.9300 | Test Acc: 0.9043\n",
      "Distilled Student | Step 2500/15000 | Train Acc: 0.9200 | Test Acc: 0.9118\n",
      "Distilled Student | Step 3000/15000 | Train Acc: 0.9200 | Test Acc: 0.9136\n",
      "Distilled Student | Step 3500/15000 | Train Acc: 0.8800 | Test Acc: 0.9172\n",
      "Distilled Student | Step 4000/15000 | Train Acc: 0.9200 | Test Acc: 0.9188\n",
      "Distilled Student | Step 4500/15000 | Train Acc: 0.9200 | Test Acc: 0.9152\n",
      "Distilled Student | Step 5000/15000 | Train Acc: 0.9600 | Test Acc: 0.9166\n",
      "Distilled Student | Step 5500/15000 | Train Acc: 0.9100 | Test Acc: 0.9206\n",
      "Distilled Student | Step 6000/15000 | Train Acc: 0.9100 | Test Acc: 0.9220\n",
      "Distilled Student | Step 6500/15000 | Train Acc: 0.9300 | Test Acc: 0.9196\n",
      "Distilled Student | Step 7000/15000 | Train Acc: 0.9200 | Test Acc: 0.9236\n",
      "Distilled Student | Step 7500/15000 | Train Acc: 0.9100 | Test Acc: 0.9229\n",
      "Distilled Student | Step 8000/15000 | Train Acc: 0.9400 | Test Acc: 0.9191\n",
      "Distilled Student | Step 8500/15000 | Train Acc: 0.9700 | Test Acc: 0.9224\n",
      "Distilled Student | Step 9000/15000 | Train Acc: 0.9400 | Test Acc: 0.9258\n",
      "Distilled Student | Step 9500/15000 | Train Acc: 0.9700 | Test Acc: 0.9274\n",
      "Distilled Student | Step 10000/15000 | Train Acc: 0.9300 | Test Acc: 0.9284\n",
      "Distilled Student | Step 10500/15000 | Train Acc: 0.9200 | Test Acc: 0.9247\n",
      "Distilled Student | Step 11000/15000 | Train Acc: 0.9400 | Test Acc: 0.9299\n",
      "Distilled Student | Step 11500/15000 | Train Acc: 0.9100 | Test Acc: 0.9297\n",
      "Distilled Student | Step 12000/15000 | Train Acc: 0.9600 | Test Acc: 0.9323\n",
      "Distilled Student | Step 12500/15000 | Train Acc: 0.9600 | Test Acc: 0.9323\n",
      "Distilled Student | Step 13000/15000 | Train Acc: 0.9600 | Test Acc: 0.9332\n",
      "Distilled Student | Step 13500/15000 | Train Acc: 0.8800 | Test Acc: 0.9354\n",
      "Distilled Student | Step 14000/15000 | Train Acc: 0.9100 | Test Acc: 0.9370\n",
      "Distilled Student | Step 14500/15000 | Train Acc: 0.9300 | Test Acc: 0.9365\n",
      "Distilled Student | Step 15000/15000 | Train Acc: 0.9300 | Test Acc: 0.9355\n",
      "Distilled student model saved to ./models/student_a0.5_t1.ckpt\n",
      "Comparison graph for student models saved as student_models_accuracy_comparison.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "\n",
    "class MnistNetworkTeacher(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistNetworkTeacher, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 625)\n",
    "        self.fc2 = nn.Linear(625, 10)\n",
    "\n",
    "    def forward(self, input_tensor, keep_prob_conv, keep_prob_hidden):\n",
    "        x = F.relu(self.conv1(input_tensor))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.dropout(x, p=1 - keep_prob_conv, training=self.training)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.dropout(x, p=1 - keep_prob_conv, training=self.training)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.dropout(x, p=1 - keep_prob_conv, training=self.training)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=1 - keep_prob_hidden, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class MnistNetworkStudent(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistNetworkStudent, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        x = torch.flatten(input_tensor, 1)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def loss_and_accuracy(prediction, target):\n",
    "    cross_entropy = torch.mean(-torch.sum(target * torch.log(prediction + 1e-12), dim=1))\n",
    "    correct_prediction = torch.eq(torch.argmax(prediction, dim=1), torch.argmax(target, dim=1))\n",
    "    accuracy = torch.mean(correct_prediction.float())\n",
    "    return cross_entropy, accuracy\n",
    "\n",
    "def to_one_hot(labels, num_classes=10):\n",
    "    return torch.eye(num_classes, device=labels.device)[labels]\n",
    "\n",
    "def calculate_test_accuracy(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "            if isinstance(model, MnistNetworkTeacher):\n",
    "                logits = model(batch_x, 1.0, 1.0)\n",
    "            else:\n",
    "                logits = model(batch_x)\n",
    "                \n",
    "            probabilities = F.softmax(logits, dim=1)\n",
    "            predicted = torch.argmax(probabilities, 1)\n",
    "            \n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "            \n",
    "    return correct / total\n",
    "\n",
    "# Функция для рисования графика точности одной модели\n",
    "def plot_single_model_history(history, model_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history['steps'], history['train_accuracies'], label='Train Accuracy')\n",
    "    plt.plot(history['steps'], history['test_accuracies'], label='Test Accuracy')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'{model_name} - Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0.8, 1.02)\n",
    "    plt.tight_layout()\n",
    "    filename = model_name.replace(\" \", \"_\").lower() + \"_accuracy_history.png\"\n",
    "    plt.savefig(filename)\n",
    "    print(f\"Accuracy graph for {model_name} saved as {filename}\")\n",
    "    plt.close()\n",
    "\n",
    "# Функция для рисования сравнительного графика точности\n",
    "def plot_student_comparison(histories):\n",
    "    colors = ['orange', 'green', 'red']\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    # Train Accuracies\n",
    "    for i, (name, history) in enumerate(histories.items()):\n",
    "        plt.plot(history['steps'], history['train_accuracies'], label=f'{name} (Train)', color=colors[i], linestyle='-')\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    # Test Accuracies\n",
    "    for i, (name, history) in enumerate(histories.items()):\n",
    "        plt.plot(history['steps'], history['test_accuracies'], label=f'{name} (Test)', color=colors[i], linestyle='--')\n",
    "\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Student Models: Accuracy Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0.8, 1.02)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = \"student_models_accuracy_comparison.png\"\n",
    "    plt.savefig(filename)\n",
    "    print(f\"Comparison graph for student models saved as {filename}\")\n",
    "    plt.close()\n",
    "\n",
    "def train_teacher():\n",
    "    print(\"\\n--- Teacher Training ---\")\n",
    "    start_lr, decay, steps_total, verbose_step = 1e-4, 1e-6, 15000, 500\n",
    "    MODEL_SAVE_PATH = './models/teacher1.ckpt'\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    mnist_train = datasets.MNIST(\"MNIST_data/\", train=True, download=True, transform=transform)\n",
    "    mnist_test = datasets.MNIST(\"MNIST_data/\", train=False, download=True, transform=transform)\n",
    "    train_loader = DataLoader(mnist_train, batch_size=128, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(mnist_test, batch_size=256, shuffle=False)\n",
    "\n",
    "    teacher = MnistNetworkTeacher().to(device)\n",
    "    optimizer = torch.optim.RMSprop(teacher.parameters(), lr=start_lr, weight_decay=decay)\n",
    "\n",
    "    history = {'steps': [], 'train_accuracies': [], 'test_accuracies': []}\n",
    "\n",
    "    teacher.train()\n",
    "    step = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            if step >= steps_total: done = True; break\n",
    "            \n",
    "            teacher.train()\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            y_one_hot = to_one_hot(batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits_teacher = teacher(batch_x, keep_prob_conv=0.8, keep_prob_hidden=0.5)\n",
    "            y_conv_teacher = F.softmax(logits_teacher, dim=1)\n",
    "            loss, acc = loss_and_accuracy(y_conv_teacher, y_one_hot)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (step + 1) % verbose_step == 0:\n",
    "                test_acc_val = calculate_test_accuracy(teacher, test_loader)\n",
    "                \n",
    "                history['steps'].append(step + 1)\n",
    "                history['train_accuracies'].append(acc.item())\n",
    "                history['test_accuracies'].append(test_acc_val)\n",
    "                \n",
    "                print(f\"Teacher | Step {step+1}/{steps_total} | Train Acc: {acc.item():.4f} | Test Acc: {test_acc_val:.4f}\")\n",
    "            \n",
    "            step += 1\n",
    "            \n",
    "    print(\"--- Teacher Training Finished ---\")\n",
    "    os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
    "    torch.save(teacher.state_dict(), MODEL_SAVE_PATH)\n",
    "    print(f\"Teacher model saved to {MODEL_SAVE_PATH}\")\n",
    "    return history\n",
    "\n",
    "def train_student_baseline():\n",
    "    print(\"\\n--- Baseline Student Training ---\")\n",
    "    steps_total, verbose_step = 15000, 500\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    mnist_train = datasets.MNIST(\"MNIST_data/\", train=True, download=True, transform=transform)\n",
    "    mnist_test = datasets.MNIST(\"MNIST_data/\", train=False, download=True, transform=transform)\n",
    "    train_loader = DataLoader(mnist_train, batch_size=100, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(mnist_test, batch_size=256, shuffle=False)\n",
    "\n",
    "    student = MnistNetworkStudent().to(device)\n",
    "    optimizer = torch.optim.SGD(student.parameters(), lr=0.1)\n",
    "\n",
    "    history = {'steps': [], 'train_accuracies': [], 'test_accuracies': []}\n",
    "\n",
    "    student.train()\n",
    "    step = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            if step >= steps_total: done = True; break\n",
    "            \n",
    "            student.train()\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            y_one_hot = to_one_hot(batch_y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits_student = student(batch_x)\n",
    "            y_student_hard = F.softmax(logits_student, dim=1)\n",
    "            loss, acc = loss_and_accuracy(y_student_hard, y_one_hot)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (step + 1) % verbose_step == 0:\n",
    "                test_acc_val = calculate_test_accuracy(student, test_loader)\n",
    "                \n",
    "                history['steps'].append(step + 1)\n",
    "                history['train_accuracies'].append(acc.item())\n",
    "                history['test_accuracies'].append(test_acc_val)\n",
    "                \n",
    "                print(f\"Baseline Student | Step {step+1}/{steps_total} | Train Acc: {acc.item():.4f} | Test Acc: {test_acc_val:.4f}\")\n",
    "\n",
    "            step += 1\n",
    "            \n",
    "    print(\"--- Baseline Student Training Finished ---\")\n",
    "    return student, history\n",
    "\n",
    "def train_student_distilled(alpha: float, temperature: int):\n",
    "    title = f\"Distilled Student: alpha={alpha}, temp={temperature}\"\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "    \n",
    "    steps_total, verbose_step = 15000, 500\n",
    "    TEACHER_MODEL_PATH, STUDENT_SAVE_PATH = './models/teacher1.ckpt', f'./models/student_a{alpha}_t{temperature}.ckpt'\n",
    "    \n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    mnist_train = datasets.MNIST(\"MNIST_data/\", train=True, download=True, transform=transform)\n",
    "    mnist_test = datasets.MNIST(\"MNIST_data/\", train=False, download=True, transform=transform)\n",
    "    train_loader = DataLoader(mnist_train, batch_size=100, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(mnist_test, batch_size=256, shuffle=False)\n",
    "\n",
    "    teacher = MnistNetworkTeacher().to(device)\n",
    "    try:\n",
    "        teacher.load_state_dict(torch.load(TEACHER_MODEL_PATH, map_location=device))\n",
    "        teacher.eval()\n",
    "        print(\"Teacher model loaded.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Teacher model not found. Please run teacher training first.\")\n",
    "        return None, None\n",
    "\n",
    "    student = MnistNetworkStudent().to(device)\n",
    "    optimizer = torch.optim.SGD(student.parameters(), lr=0.1)\n",
    "    \n",
    "    history = {'steps': [], 'train_accuracies': [], 'test_accuracies': []}\n",
    "\n",
    "    student.train()\n",
    "    step = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            if step >= steps_total: done = True; break\n",
    "            \n",
    "            student.train()\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            y_one_hot = to_one_hot(batch_y)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                logits_teacher = teacher(batch_x, 1.0, 1.0)\n",
    "                y_teacher_soft = F.softmax(logits_teacher / temperature, dim=1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits_student = student(batch_x)\n",
    "            \n",
    "            y_student_hard = F.softmax(logits_student, dim=1)\n",
    "            y_student_soft = F.softmax(logits_student / temperature, dim=1)\n",
    "            \n",
    "            loss_hard, acc = loss_and_accuracy(y_student_hard, y_one_hot)\n",
    "            loss_soft, _ = loss_and_accuracy(y_student_soft, y_teacher_soft)\n",
    "            \n",
    "            total_loss = loss_hard * alpha + loss_soft * (1 - alpha) * (temperature ** 2)\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (step + 1) % verbose_step == 0:\n",
    "                test_acc_val = calculate_test_accuracy(student, test_loader)\n",
    "\n",
    "                history['steps'].append(step + 1)\n",
    "                history['train_accuracies'].append(acc.item())\n",
    "                history['test_accuracies'].append(test_acc_val)\n",
    "                \n",
    "                print(f\"Distilled Student | Step {step+1}/{steps_total} | Train Acc: {acc.item():.4f} | Test Acc: {test_acc_val:.4f}\")\n",
    "\n",
    "            step += 1\n",
    "\n",
    "    os.makedirs(os.path.dirname(STUDENT_SAVE_PATH), exist_ok=True)\n",
    "    torch.save(student.state_dict(), STUDENT_SAVE_PATH)\n",
    "    print(f\"Distilled student model saved to {STUDENT_SAVE_PATH}\")\n",
    "    return student, history\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    teacher_history = train_teacher()\n",
    "\n",
    " \n",
    "    plot_single_model_history(teacher_history, \"Teacher Model\")\n",
    "    \n",
    "    student_histories = {}\n",
    "    \n",
    "    _, baseline_history = train_student_baseline()\n",
    "    student_histories['Baseline'] = baseline_history\n",
    "    \n",
    "    _, distilled_history1 = train_student_distilled(alpha=0.08, temperature=7)\n",
    "    if distilled_history1:\n",
    "        student_histories['Distilled (a=0.08, t=7)'] = distilled_history1\n",
    "    \n",
    "    _, distilled_history2 = train_student_distilled(alpha=0.5, temperature=1)\n",
    "    if distilled_history2:\n",
    "        student_histories['Distilled (a=0.5, t=1)'] = distilled_history2\n",
    "\n",
    "    plot_student_comparison(student_histories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1757f15-0ef4-47a7-9899-e2f6c7601f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
